{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "First we will import all the required libraries required for web-scraping.\n",
    "We will require two libraries for web-scraping:\n",
    "\n",
    "1. requests: This will be used to send get request to the web page server to get the source-code of the webpage\n",
    "\n",
    "2. BeautifulSoup: It will be used to parse the source code and to extract the required data from the parsed structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Write a python program to display all the header tags from  ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_soup=BeautifulSoup(wiki.content)\n",
    "title_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(title_soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=title_soup.find_all('h2',class_=\"mp-h2\") \n",
    "wiki_titles=[] \n",
    "for i in titles:\n",
    "    wiki_titles.append(i.text)\n",
    "wiki_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_movies(url):\n",
    "    Name=[]\n",
    "    Rating=[]\n",
    "    Year=[]\n",
    "    imdb_page=requests.get(url)\n",
    "    imdb_soup=BeautifulSoup(imdb_page.content,'html.parser')\n",
    "    \n",
    "    imdb_name=imdb_soup.find_all('td',class_=\"titleColumn\")\n",
    "    for i in imdb_name:\n",
    "        for j in i.find_all('a'):\n",
    "             Name.append(j.text.replace(\"/n\",\" \").replace(\"\\n\",\"\"))\n",
    "        \n",
    "       \n",
    "    imdb_rating=imdb_soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "    for i in imdb_rating:\n",
    "        Rating.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    imdb_year=imdb_soup.find_all('span',class_=\"secondaryInfo\")\n",
    "    for i in imdb_year:\n",
    "        Year.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "    import pandas as pd\n",
    "    movies=pd.DataFrame({})\n",
    "    movies['Names']=Name\n",
    "    movies['Ratings']=Rating\n",
    "    movies['Years']=Year\n",
    "    movies=movies[:100]\n",
    "    return(movies)\n",
    "\n",
    "imdb_movies_list=imdb_movies('https://www.imdb.com/chart/top/')\n",
    "imdb_movies_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(url.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie =soup.find_all('td',class_=\"titleColumn\")\n",
    "Name=[]\n",
    "for i in movie:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        Name.append(j.text.replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_rating =soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "Rating=[]\n",
    "for i in imdb_rating:\n",
    "        Rating.append(i.text.replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_year =soup.find_all('span',class_=\"secondaryInfo\")\n",
    "year=[]\n",
    "for i in imdb_year:\n",
    "        year.append(i.text.replace(\"\\n\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "India_Movie=pd.DataFrame({})\n",
    "India_Movie['Name']=Name\n",
    "India_Movie['Rating']=Rating\n",
    "India_Movie['Year']=year\n",
    "India_Movie=India_Movie[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "India_Movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book(url):\n",
    "    book_names=[]\n",
    "    author_name=[]\n",
    "    genres=[]\n",
    "    review=[]\n",
    "    \n",
    "    book_page=requests.get(url)\n",
    "    book_soup=BeautifulSoup(book_page.content,'html.parser')\n",
    "    \n",
    "    bookpage=book_soup.find_all('h4',class_='italic')\n",
    "    for i in bookpage:\n",
    "        book_names.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "    book_author=book_soup.find_all(\"p\",class_=\"sans bold\")\n",
    "    for i in book_author:\n",
    "        author_name.append(i.text.replace(\"\\n\",\" \"))\n",
    "        \n",
    "    book_genres = book_soup.find_all(\"p\",class_=\"genre-links hidden-phone\")    \n",
    "    for i in book_genres:\n",
    "            genres.append(i.text.replace(\"\\n\",\" \"))\n",
    "            \n",
    "    book_review = book_soup.find_all(\"p\",class_=\"excerpt\") \n",
    "    for i in book_review:\n",
    "        review.append(i.text.replace(\"\\n\",\" \"))    \n",
    " \n",
    "                                      \n",
    "    import pandas as pd \n",
    "    book=pd.DataFrame({})\n",
    "    book['Book Name']=book_names\n",
    "    book['Author Name'] = author_name\n",
    "    book['Genres'] = genres\n",
    "    book['Review'] = review                                  \n",
    "    book=book.head()\n",
    "    return(book)\n",
    "\n",
    "Book_Page=book(\"https://bookpage.com/reviews\")\n",
    "Book_Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "    i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "    ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "    iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_teams(url):\n",
    "    teams=[]\n",
    "    matches=[]\n",
    "    points = []\n",
    "    rating =[]\n",
    "    \n",
    "    odi_team =requests.get(url)\n",
    "    soup=BeautifulSoup(odi_team.content,'html.parser')\n",
    "    \n",
    "# First Row of the table\n",
    "    team= soup.find_all(\"span\",class_=\"u-hide-phablet\")\n",
    "    for i in team:\n",
    "            teams.append(i.text.replace(\"\\n\",\" \"))  \n",
    "#                         \n",
    "    team = soup.find_all(\"td\",class_=\"table-body__cell rankings-table__team\")           \n",
    "    for i in team:\n",
    "            teams.append(i.text.replace(\"\\n\",\" \"))\n",
    "                               \n",
    "                               \n",
    "# First Row of the table    \n",
    "    odi_match=soup.find_all(\"td\",class_=\"rankings-block__banner--matches\")\n",
    "    for i in odi_match:\n",
    "          matches.append(i.text.replace(\"\\n\",\" \"))   \n",
    "#Other rows in the table                              \n",
    "    odi_match =soup.find_all(\"td\",class_=\"table-body__cell u-center-text\")\n",
    "    for i in odi_match:\n",
    "          matches.append(i.text.replace(\"\\n\",\" \"))                         \n",
    "                               \n",
    "                            \n",
    "                                                       \n",
    "# First Row of the table\n",
    "                               \n",
    "    odi_points = soup.find_all(\"td\",class_=\"rankings-block__banner--points\") \n",
    "    for i in odi_points:\n",
    "        points.append(i.text.replace(\"\\n\",\" \"))\n",
    "#Other rows in the table                               \n",
    "    odi_points = soup.find_all(\"td\",class_=\"table-body__cell u-center-text\")                          \n",
    "    for i in odi_points:\n",
    "        points.append(i.text.replace(\"\\n\",\" \"))\n",
    "                               \n",
    "                               \n",
    "# First Row of the table\n",
    "                               \n",
    "    odi_rating = soup.find_all(\"td\",class_=\"rankings-block__banner--rating u-text-right\") \n",
    "    for i in odi_rating:\n",
    "        rating.append(i.text.replace(\"\\n\",\" \"))\n",
    "#Other rows in the table                               \n",
    "    odi_rating = soup.find_all(\"td\",class_=\"table-body__cell u-text-right rating\")                          \n",
    "    for i in odi_rating:\n",
    "        rating.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    odi_teams=pd.DataFrame({})                          \n",
    "    odi_teams['Teams']=  teams[:10]  \n",
    "    odi_teams['Matches']=matches[:10]\n",
    "    odi_teams['Points']= points [:10]                \n",
    "    odi_teams['Rating']=rating[:10]\n",
    "    odi_teams.head(10)\n",
    "    return(odi_teams)                                                              \n",
    "                               \n",
    "\n",
    "ODI_men_team= odi_teams(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "\n",
    "ODI_men_team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii). Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_batsmen(url):\n",
    "    player=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    \n",
    "    page=requests.get(url)\n",
    "    soup=BeautifulSoup(page.content,'html.parser')\n",
    "    \n",
    "# First Row of the table\n",
    "    odi_player=soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in odi_player:\n",
    "        player.append(i.text)\n",
    "    \n",
    "# Other rows in the table\n",
    "    odi_player=soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in odi_player:\n",
    "        player.append(i.find('a').text)\n",
    "    \n",
    "    \n",
    "# First Row of the table\n",
    "    odi_team=soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "# Other rows in the table\n",
    "    odi_team=soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "    \n",
    "# First Row of the table\n",
    "    odi_rating=soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "# Other rows in the table\n",
    "    odi_rating=soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    odi_batsmen=pd.DataFrame({})\n",
    "    odi_batsmen['Player']=player [:10]\n",
    "    odi_batsmen['Teams']=teams [:10]\n",
    "    odi_batsmen['Ratings']=ratings [:10]\n",
    "    return(odi_batsmen) \n",
    "        \n",
    "   \n",
    "top_odi_batsmen = odi_batsmen('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "top_odi_batsmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii). Top 10 ODI bowlers along with the records of their team and rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_bowler(url):\n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    bowler_page=requests.get(url)\n",
    "    bowler_soup=BeautifulSoup(bowler_page.content,'html.parser')\n",
    "    \n",
    "# First Row of the table\n",
    "    odi_player=bowler_soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in odi_player:\n",
    "        players.append(i.text)\n",
    "    \n",
    "# Other rows in the table\n",
    "    odi_player=bowler_soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in odi_player:\n",
    "        for j in i.find_all(\"a\"):\n",
    "            players.append(j.text.replace(\"\\n\", \" \"))\n",
    "\n",
    "\n",
    "# First Row of the table\n",
    "    odi_team=bowler_soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "#Other rows in the table\n",
    "    odi_team=bowler_soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    " \n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_rating=bowler_soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "        \n",
    "#Other rows in the table\n",
    "    odi_rating=bowler_soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    odi_bowler=pd.DataFrame({})\n",
    "    odi_bowler['Players']=players [:10]\n",
    "    odi_bowler['Teams']=teams [:10]\n",
    "    odi_bowler['Ratings']=ratings [:10]\n",
    "    return(odi_bowler)\n",
    "\n",
    "odi_top_bowler=odi_bowler('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "odi_top_bowler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "    i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "    ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "    iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_women_team(url):\n",
    "    teams=[]\n",
    "    matches=[]\n",
    "    points=[]\n",
    "    ratings=[]\n",
    "    odi_team_page=requests.get(url)\n",
    "    odi_team_soup=BeautifulSoup(odi_team_page.content,'html.parser')\n",
    "    \n",
    "    odi_team=odi_team_soup.find_all('span',class_='u-hide-phablet')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text)\n",
    "    \n",
    "#For first row of the table\n",
    "    \n",
    "    match_row=odi_team_soup.find_all('td',class_='rankings-block__banner--matches')\n",
    "    for i in match_row:\n",
    "        matches.append(i.text.replace('\\n',''))\n",
    "\n",
    "               \n",
    "# For other rows of the table\n",
    "    match_row=odi_team_soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in match_row:\n",
    "        matches.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "    \n",
    "#For first row of the table\n",
    "    odi_point=odi_team_soup.find_all('td',class_='rankings-block__banner--points')\n",
    "    for i in odi_point:\n",
    "        points.append(i.text.replace('\\n',''))\n",
    "        \n",
    "#For other rows of the table   \n",
    "    odi_point=odi_team_soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in odi_point:\n",
    "        points.append(i.text.replace('\\n',''))\n",
    "    \n",
    "#For first row    \n",
    "    odi_rating=odi_team_soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text.replace('\\n',''))\n",
    "        \n",
    "#For other rows of the table  \n",
    "    odi_rating=odi_team_soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    teams_odi=pd.DataFrame({})\n",
    "    teams_odi['Teams']=teams [:10]\n",
    "    teams_odi['Matches']=matches [:10]\n",
    "    teams_odi['Points']=points [:10]\n",
    "    teams_odi['Ratings']=ratings [:10]\n",
    "    return(teams_odi)\n",
    "\n",
    "ODI_team_women=odi_women_team('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "ODI_team_women    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii) Top 10 women’s ODI players along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_women(url):\n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    batsmen_page=requests.get(url)\n",
    "    batsmen_soup=BeautifulSoup(batsmen_page.content,'html.parser')\n",
    "    \n",
    "# First Row of the table\n",
    "    odi_player=batsmen_soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in odi_player:\n",
    "        players.append(i.text.replace('\\n',''))\n",
    "    \n",
    "# Other rows in the table\n",
    "    odi_player=batsmen_soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in odi_player:\n",
    "        for j in i.find_all('a'):\n",
    "            players.append(j.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "# First Row of the table\n",
    "    odi_team=batsmen_soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "#  Other rows in the table\n",
    "    odi_team=batsmen_soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    \n",
    "# First Row of the table\n",
    "    odi_team=batsmen_soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "#  Other rows in the table\n",
    "    odi_team=batsmen_soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    " \n",
    "    \n",
    "# First Row of the table\n",
    "    odi_rating=batsmen_soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "#  Other rows in the table\n",
    "    odi_rating=batsmen_soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    batsmen_odi=pd.DataFrame({})\n",
    "    batsmen_odi['Players']=players [:10]\n",
    "    batsmen_odi['Teams']=teams[:10]\n",
    "    batsmen_odi['Ratings']=ratings [:10]\n",
    "    return(batsmen_odi)\n",
    "\n",
    "top10_odi_batsmen=odi_women('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "top10_odi_batsmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_women_allrounder(url):\n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    bowler_page=requests.get(url)\n",
    "    bowler_soup=BeautifulSoup(bowler_page.content,'html.parser')\n",
    "    \n",
    "# First Row of the table\n",
    "    odi_player=bowler_soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in odi_player:\n",
    "        players.append(i.text)\n",
    "    \n",
    "# Other rows in the table\n",
    "    odi_player=bowler_soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in odi_player:\n",
    "        for j in i.find_all('a'):\n",
    "            players.append(j.text)\n",
    " \n",
    "# First Row of the table\n",
    "    odi_team=bowler_soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "#  Other rows in the table\n",
    "    odi_team=bowler_soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "\n",
    "    \n",
    "# First Row of the table\n",
    "    odi_rating=bowler_soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "#  Other rows in the table\n",
    "    odi_rating=bowler_soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "\n",
    "    import pandas as pd\n",
    "    bowler_odi=pd.DataFrame({})\n",
    "    bowler_odi['Players']=players [:10]\n",
    "    bowler_odi['Teams']=teams [:10]\n",
    "    bowler_odi['Ratings']=ratings [:10]\n",
    "    return(bowler_odi)\n",
    "\n",
    "\n",
    "top10_odi_bowler=odi_women_allrounder('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "top10_odi_bowler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_page=requests.get('https://www.amazon.in/best-mobile-under-20000/s?k=best+mobile+under+20000')\n",
    "amazon_soup= BeautifulSoup(amazon_page.content,'html.parser')\n",
    "\n",
    "Product=[] \n",
    "Price=[]\n",
    "Rating=[]\n",
    "Image=[]\n",
    "\n",
    "\n",
    "\n",
    "item= amazon_soup.find_all('span',class_=\"a-size-medium a-color-base a-text-normal\")\n",
    "for i in item:\n",
    "    Product.append(i.text)\n",
    "    \n",
    "price= amazon_soup.find_all('span',class_=\"a-price-whole\")\n",
    "for i in price:\n",
    "    Price.append(i.text)\n",
    "    \n",
    "rating= amazon_soup.find_all('i',class_=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\")\n",
    "for i in rating:\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "    \n",
    "image= amazon_soup.find_all('div', class_='a-section aok-relative s-image-fixed-height')\n",
    "for i in image:\n",
    "    for j in i.find_all('img'):\n",
    "         Image.append(i)\n",
    "    \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "Mobiles=pd.DataFrame({})\n",
    "Mobiles['Product']=Product [:10]\n",
    "Mobiles['Price']=Price [:10]\n",
    "Mobiles['Image']=Image [:10]\n",
    "Mobiles['Rating']=Rating [:10]\n",
    "Mobiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.  Write a python program to extract information about the local weather from the National Weather Service \n",
    "website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day \n",
    "extended forecast display for the city. The data should include period, short description, temperature and \n",
    "description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(url):\n",
    "    time=[]\n",
    "    weekly_climate=[]\n",
    "    temp=[]\n",
    "    description=[]\n",
    "    weather_page=requests.get(url)\n",
    "    weather_soup=BeautifulSoup(weather_page.content,'html.parser')\n",
    "    \n",
    "    weather_time=weather_soup.find_all(\"p\",class_=\"period-name\")\n",
    "    for i in weather_time:\n",
    "       time.append(i.text)\n",
    "\n",
    "    climate=weather_soup.find_all(\"p\",class_=\"short-desc\")\n",
    "    for i in climate:\n",
    "        weekly_climate.append(i.text)\n",
    "    weekly_climate\n",
    "\n",
    "    weather_temp=weather_soup.find_all(\"p\",class_=\"temp temp-high\")\n",
    "    for i in weather_temp:\n",
    "         temp.append(i.text)\n",
    "\n",
    "    weather_temp=weather_soup.find_all(\"p\",class_=\"temp temp-low\")\n",
    "    for i in weather_temp:\n",
    "        temp.append(i.text)\n",
    "\n",
    "    weather_description=weather_soup.find_all(\"div\",class_=\"col-sm-10 forecast-text\")\n",
    "    for i in weather_description:\n",
    "        description.append(i.text)\n",
    "\n",
    "    import pandas as pd\n",
    "    weather=pd.DataFrame({})\n",
    "    weather[\"weather_time\"]=time[:8]\n",
    "    weather[\"Climate\"]=weekly_climate[:8]\n",
    "    weather[\"Temperature\"]=temp[:8]\n",
    "    weather[\"Description\"]=description[:8]\n",
    "    return(weather)\n",
    "\n",
    "weather(\"https://forecast.weather.gov/MapClick.php?lat=37.7771&lon=-122.4196#.YF4e9j_hVPY\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title,  company name, CTC, and apply date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internshala(url):\n",
    "    job_title=[]\n",
    "    company =[]  \n",
    "    CTC=[]\n",
    "    apply_by=[]\n",
    "    \n",
    "    intershala_page = requests.get(url)\n",
    "    intershala_soup = BeautifulSoup(intershala_page.content,'html.parser')\n",
    "    \n",
    "    fresher_job = intershala_soup.find_all(\"div\",class_=\"heading_4_5 profile\")\n",
    "    for i in fresher_job:\n",
    "        job_title.append(i.text.replace(\"\\n\",\" \"))\n",
    "    \n",
    "\n",
    "    company_name = intershala_soup.find_all(\"div\",class_=\"heading_6 company_name\")\n",
    "    for i in company_name:\n",
    "        company.append(i.text.replace(\"\\n\",\" \"))    \n",
    "    \n",
    "\n",
    "    annual_salary = intershala_soup.find_all(\"div\",class_=\"other_detail_item\")\n",
    "    for i in range(1,len(annual_salary),3):\n",
    "         CTC.append(annual_salary[i].text.replace(\"\\n\",'').replace('CTC',''))\n",
    "    \n",
    "    apply_info = intershala_soup.find_all(\"div\",class_=\"other_detail_item\")\n",
    "    for i in range(2,len(apply_info),3):\n",
    "         apply_by.append(apply_info[i].text.replace(\"\\n\",'').replace('Apply By',''))\n",
    "    \n",
    "            \n",
    "            \n",
    "    import pandas as pd\n",
    "    fresher_job = pd.DataFrame({})\n",
    "    fresher_job['Job-title']=job_title [:10]\n",
    "    fresher_job['Company_Name']=company [:10]\n",
    "    fresher_job['CTC']=CTC [:10]\n",
    "    fresher_job[\"Apply_By\"]=apply_by [:10]\n",
    "    \n",
    "    return(fresher_job)\n",
    "\n",
    "internshala(\"https://internshala.com/fresher-jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Write a python program to scrape house details from mentioned url. It should include house title, location, area, emi and price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_name = []\n",
    "location_name = []\n",
    "area = []\n",
    "month_EMI = []\n",
    "price = []\n",
    "page = requests.get(\"https://www.nobroker.in/property/sale/bangalore/Electronic%20City/?searchParam=W3sibGF0IjoxMi44MzU3MTAyMzE0MTQyLCJsb24iOjc3LjY3MzI3MDk3MzgyMTcsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkiLCJzaG93TWFwIjpmYWxzZX1d&type=BHK4\")\n",
    "house_soup=BeautifulSoup(page.content)\n",
    "\n",
    "title = house_soup.find_all(\"h2\",class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "for i in title:\n",
    "    for j in i.find_all('span'):\n",
    "        title_name.append(j.text)\n",
    "        \n",
    "location = house_soup.find_all(\"div\",class_=\"nb__2CMjv\")\n",
    "for i in location:\n",
    "    location_name.append(i.text)\n",
    "    \n",
    "house_area = house_soup.find_all(\"div\",class_=\"nb__3oNyC\")\n",
    "for i in house_area:\n",
    "    area.append(i.text)\n",
    "    \n",
    "month_payment = house_soup.find_all(\"div\",id=\"roomType\")\n",
    "for i in month_payment:\n",
    "    month_EMI.append(i.text)\n",
    "    \n",
    "house_price = house_soup.find_all(\"div\",id=\"minDeposit\")\n",
    "for i in house_price:\n",
    "        price.append(i.text)\n",
    "        \n",
    "import pandas as pd\n",
    "broker=pd.DataFrame({})\n",
    "broker['House_Tittle']= title_name\n",
    "broker['Location']= location_name\n",
    "broker['Area'] = area\n",
    "broker['EMI'] =month_EMI\n",
    "broker['Price'] =price\n",
    "broker=broker[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
