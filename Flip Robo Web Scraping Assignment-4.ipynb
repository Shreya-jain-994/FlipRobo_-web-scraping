{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required library\n",
    "from selenium import webdriver # To access the browser and website\n",
    "import pandas as pd  # To format the strutured data\n",
    "import time # To pause/hold the step by step process\n",
    "\n",
    "# EXception lib\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[25]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[30]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Bath Song\"[31]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[32]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Uptown Funk\"[33]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"Gangnam Style\"[34]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>\"Phonics Song with Two Words\"[36]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>\"Sugar\"[37]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>\"Dame Tu Cosita\"[38]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>\"Sorry\"[39]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>\"Counting Stars\"[41]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>\"Thinking Out Loud\"[42]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>\"Wheels on the Bus\"[43]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>\"Dark Horse\"[44]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>\"Faded\"[45]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>\"Shake It Off\"[46]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>\"Girls Like You\"[47]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>\"Lean On\"[48]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>\"Bailando\"[49]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>\"Mi Gente\"[51]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>\"Perfect\"[52]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>\"Axel F\"[53]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[54]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>\"Hello\"[55]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0     1                           \"Baby Shark Dance\"[22]   \n",
       "1     2                                  \"Despacito\"[24]   \n",
       "2     3                       \"Johny Johny Yes Papa\"[25]   \n",
       "3     4                               \"Shape of You\"[26]   \n",
       "4     5                              \"See You Again\"[27]   \n",
       "5     6   \"Masha and the Bear – Recipe for Disaster\"[30]   \n",
       "6     7                                  \"Bath Song\"[31]   \n",
       "7     8  \"Learning Colors – Colorful Eggs on a Farm\"[32]   \n",
       "8     9                                \"Uptown Funk\"[33]   \n",
       "9    10                              \"Gangnam Style\"[34]   \n",
       "10   11                \"Phonics Song with Two Words\"[36]   \n",
       "11   12                                      \"Sugar\"[37]   \n",
       "12   13                             \"Dame Tu Cosita\"[38]   \n",
       "13   14                                      \"Sorry\"[39]   \n",
       "14   15                                       \"Roar\"[40]   \n",
       "15   16                             \"Counting Stars\"[41]   \n",
       "16   17                          \"Thinking Out Loud\"[42]   \n",
       "17   18                          \"Wheels on the Bus\"[43]   \n",
       "18   19                                 \"Dark Horse\"[44]   \n",
       "19   20                                      \"Faded\"[45]   \n",
       "20   21                               \"Shake It Off\"[46]   \n",
       "21   22                             \"Girls Like You\"[47]   \n",
       "22   23                                    \"Lean On\"[48]   \n",
       "23   24                                   \"Bailando\"[49]   \n",
       "24   25                                 \"Let Her Go\"[50]   \n",
       "25   26                                   \"Mi Gente\"[51]   \n",
       "26   27                                    \"Perfect\"[52]   \n",
       "27   28                                     \"Axel F\"[53]   \n",
       "28   29           \"Waka Waka (This Time for Africa)\"[54]   \n",
       "29   30                                      \"Hello\"[55]   \n",
       "\n",
       "                            Artist        Upload_Date Views  \n",
       "0   Pinkfong Kids' Songs & Stories      June 17, 2016  9.04  \n",
       "1                       Luis Fonsi   January 12, 2017  7.46  \n",
       "2                      LooLoo Kids    October 8, 2016  5.58  \n",
       "3                       Ed Sheeran   January 30, 2017  5.40  \n",
       "4                      Wiz Khalifa      April 6, 2015  5.19  \n",
       "5                       Get Movies   January 31, 2012  4.45  \n",
       "6       Cocomelon – Nursery Rhymes        May 2, 2018  4.37  \n",
       "7                      Miroshka TV  February 27, 2018  4.31  \n",
       "8                      Mark Ronson  November 19, 2014  4.24  \n",
       "9                              Psy      July 15, 2012  4.13  \n",
       "10                       ChuChu TV      March 6, 2014  4.02  \n",
       "11                        Maroon 5   January 14, 2015  3.51  \n",
       "12                       El Chombo      April 5, 2018  3.48  \n",
       "13                   Justin Bieber   October 22, 2015  3.45  \n",
       "14                      Katy Perry  September 5, 2013  3.39  \n",
       "15                     OneRepublic       May 31, 2013  3.35  \n",
       "16                      Ed Sheeran    October 7, 2014  3.29  \n",
       "17      Cocomelon – Nursery Rhymes       May 24, 2018  3.18  \n",
       "18                      Katy Perry  February 20, 2014  3.11  \n",
       "19                     Alan Walker   December 3, 2015  3.10  \n",
       "20                    Taylor Swift    August 18, 2014  3.08  \n",
       "21                        Maroon 5       May 31, 2018  3.08  \n",
       "22                     Major Lazer     March 22, 2015  3.07  \n",
       "23                Enrique Iglesias     April 11, 2014  3.07  \n",
       "24                       Passenger      July 25, 2012  3.03  \n",
       "25                        J Balvin      June 29, 2017  2.95  \n",
       "26                      Ed Sheeran   November 9, 2017  2.90  \n",
       "27                      Crazy Frog      June 16, 2009  2.90  \n",
       "28                         Shakira       June 4, 2010  2.89  \n",
       "29                           Adele   October 22, 2015  2.86  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "url=('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# creating empty list\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "Upload_Date = []\n",
    "Views = []\n",
    "\n",
    "# Fetching rank details\n",
    "rank=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[1]\")\n",
    "for i in rank:\n",
    "    try:\n",
    "        Rank.append(i.text.replace(\".\",\"\"))\n",
    "    except:\n",
    "        Rank.append(\"-\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "# Fetching name details\n",
    "\n",
    "name=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[2]\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except:\n",
    "        Name.append(\"-\")\n",
    "        \n",
    " # Fetching artist details\n",
    "       \n",
    "artist=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[3]\")\n",
    "for i in artist:\n",
    "    try:\n",
    "        Artist.append(i.text)\n",
    "    except:\n",
    "        Artist.append(\"-\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "# Fetching upload details\n",
    "\n",
    "\n",
    "upload=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[5]\")\n",
    "for i in upload:\n",
    "    try:\n",
    "        Upload_Date.append(i.text)\n",
    "    except:\n",
    "        Upload_Date.append(\"-\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "# Fetching views details\n",
    "\n",
    "\n",
    "views=driver.find_elements_by_xpath(\"//*[@id='mw-content-text']/div[1]/table[3]/tbody/tr/td[4]\")\n",
    "for i in views:\n",
    "    try:\n",
    "        Views.append(i.text)\n",
    "    except:\n",
    "        views.append(\"-\")\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "#creating a Data Frame\n",
    "Most_Viewed_Youtube_Videos=pd.DataFrame([])\n",
    "Most_Viewed_Youtube_Videos[\"Rank\"]=Rank\n",
    "Most_Viewed_Youtube_Videos[\"Name\"]=Name\n",
    "Most_Viewed_Youtube_Videos[\"Artist\"]=Artist\n",
    "Most_Viewed_Youtube_Videos[\"Upload_Date\"]=Upload_Date\n",
    "Most_Viewed_Youtube_Videos[\"Views\"]=Views\n",
    "time.sleep(1)\n",
    "Most_Viewed_Youtube_Videos"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "url=('https://www.bcci.tv/')\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# creating empty list\n",
    "Match_title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time=[]\n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "# navigating to international fixture\n",
    "international = driver.find_element_by_xpath(\"//div[@class='navigation__drop-down drop-down drop-down--reveal-on-hover']\")\n",
    "international.click()\n",
    "time.sleep(2)\n",
    "\n",
    "fixture = driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\").get_attribute('href')\n",
    "driver.get(fixture)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Match_title details\n",
    "\n",
    "\n",
    "title=driver.find_elements_by_xpath(\"/html/body/div[4]/div/div/div[2]/section/div/div/a/div[2]/div[1]/span[2]\")\n",
    "for i in title:\n",
    "    try:\n",
    "        Match_title.append(i.text)\n",
    "    except:\n",
    "        Match_title.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "# Fetching Series details\n",
    "\n",
    "name_series=driver.find_elements_by_xpath(\"//strong[@class='fixture__name fixture__name--with-margin']\")\n",
    "for i in name_series:\n",
    "    try:\n",
    "        Series.append(i.text)\n",
    "    except:\n",
    "        Series.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "# Fetching Place details\n",
    "\n",
    "        \n",
    "place_name=driver.find_elements_by_xpath(\"//p[@class='fixture__additional-info']/span\")\n",
    "for i in place_name:\n",
    "    try:\n",
    "        Place.append(i.text)\n",
    "    except:\n",
    "        Place.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "  # Fetching Date_time details\n",
    "date = driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/div/span')\n",
    "month = driver.find_elements_by_xpath('//div[@class=\"fixture__datetime desktop-only\"]/div/div/span[1]')\n",
    "for i in range(len(date)):\n",
    "    Date.append(date[i].text+month[i].text)\n",
    "time = driver.find_elements_by_xpath('//div[@class=\"fixture__full-date\"]/div/span[2]')\n",
    "for i in time:\n",
    "    Time.append(i.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>1st Test</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>2nd Test</td>\n",
       "      <td>Lord's, London</td>\n",
       "      <td>12AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>3rd Test</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "      <td>25AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>4th Test</td>\n",
       "      <td>The Oval, London</td>\n",
       "      <td>02SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>5th Test</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "      <td>10SEPTEMBER</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ENGLAND V INDIA 2021</td>\n",
       "      <td>1st Test</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "      <td>04AUGUST</td>\n",
       "      <td>15:30 IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Match_Title    Series                     Place         Date  \\\n",
       "0  ENGLAND V INDIA 2021  1st Test  Trent Bridge, Nottingham     04AUGUST   \n",
       "1  ENGLAND V INDIA 2021  2nd Test            Lord's, London     12AUGUST   \n",
       "2  ENGLAND V INDIA 2021  3rd Test         Headingley, Leeds     25AUGUST   \n",
       "3  ENGLAND V INDIA 2021  4th Test          The Oval, London  02SEPTEMBER   \n",
       "4  ENGLAND V INDIA 2021  5th Test  Old Trafford, Manchester  10SEPTEMBER   \n",
       "5  ENGLAND V INDIA 2021  1st Test  Trent Bridge, Nottingham     04AUGUST   \n",
       "\n",
       "        Time  \n",
       "0  15:30 IST  \n",
       "1  15:30 IST  \n",
       "2  15:30 IST  \n",
       "3  15:30 IST  \n",
       "4  15:30 IST  \n",
       "5  15:30 IST  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Data Frame\n",
    "India_international_fixtures=pd.DataFrame([])\n",
    "India_international_fixtures[\"Match_Title\"]=Match_title[:6]\n",
    "India_international_fixtures[\"Series\"]=Series[:6]\n",
    "India_international_fixtures[\"Place\"]=Place[:6]\n",
    "India_international_fixtures[\"Date\"]=Date[:6]\n",
    "India_international_fixtures[\"Time\"]=Time[:6]\n",
    "India_international_fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "url=(\"https://www.guru99.com/\")\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "# creating empty list\n",
    "Name = []\n",
    "Description = []\n",
    "\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting selenium topic\n",
    "driver.find_element_by_xpath(\"//*[@id='java_technologies']/li[3]/a\").click()\n",
    "time.sleep(3)\n",
    "\n",
    "search_ex=driver.find_element_by_xpath(\"//a[@title='Selenium Exception Handling (Common Exceptions List)']\")\n",
    "search_ex.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching name details\n",
    "exception=driver.find_elements_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div[1]/div/div/div/div/div/div[2]/table/tbody/tr/td[1]\")\n",
    "for i in exception:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except:\n",
    "        Name.append(\"-\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "#fetching description details\n",
    "\n",
    "description=driver.find_elements_by_xpath(\"/html/body/div[2]/section[3]/div/div[1]/main/div[1]/div/div/div/div/div/div[2]/table/tbody/tr/td[2]\")\n",
    "for i in description:\n",
    "    try:\n",
    "        Description.append(i.text)\n",
    "    except:\n",
    "        Description.append(\"-\")\n",
    "        \n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Description'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting the title entry in all the list\n",
    "Name.pop(0)\n",
    "Description.pop(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Exception  \\\n",
       "0         ElementNotSelectableException   \n",
       "1                NoSuchElementException   \n",
       "2                  NoSuchFrameException   \n",
       "3               NoAlertPresentException   \n",
       "4                 NoSuchWindowException   \n",
       "5        StaleElementReferenceException   \n",
       "6              SessionNotFoundException   \n",
       "7                      TimeoutException   \n",
       "8                    WebDriverException   \n",
       "9             ConnectionClosedException   \n",
       "10     ElementClickInterceptedException   \n",
       "11      ElementNotInteractableException   \n",
       "12             ErrorInResponseException   \n",
       "13  ErrorHandler.UnknownServerException   \n",
       "14         ImeActivationFailedException   \n",
       "15             ImeNotAvailableException   \n",
       "16         InsecureCertificateException   \n",
       "17             InvalidArgumentException   \n",
       "18         InvalidCookieDomainException   \n",
       "19          InvalidCoordinatesException   \n",
       "20          InvalidElementStateExceptio   \n",
       "21            InvalidSessionIdException   \n",
       "22       InvalidSwitchToTargetException   \n",
       "23                  JavascriptException   \n",
       "24                        JsonException   \n",
       "25             NoSuchAttributeException   \n",
       "26       MoveTargetOutOfBoundsException   \n",
       "27               NoSuchContextException   \n",
       "28                NoSuchCookieException   \n",
       "29                    NotFoundException   \n",
       "30          RemoteDriverServerException   \n",
       "31                  ScreenshotException   \n",
       "32           SessionNotCreatedException   \n",
       "33           UnableToSetCookieException   \n",
       "34           UnexpectedTagNameException   \n",
       "35              UnhandledAlertException   \n",
       "36      UnexpectedAlertPresentException   \n",
       "37               UnknownMethodException   \n",
       "38          UnreachableBrowserException   \n",
       "39          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can't be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the Data Frame\n",
    "Selenium_Exception= pd.DataFrame([])\n",
    "Selenium_Exception['Exception']=Name[:40]\n",
    "Selenium_Exception['Description']=Description[:40]\n",
    "Selenium_Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP at current price (19-20)\n",
    "D) GSDP at current price (18-19)\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "url=(\"http://statisticstimes.com/\")\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking the economy drop down\n",
    "eco_button=driver.find_element_by_xpath(\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "eco_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking the india button\n",
    "india_button=driver.find_element_by_xpath(\"//*[@id='top']/div[2]/div[2]/div/a[3]\").click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the State gdp\n",
    "state_gdp=driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_19_20</th>\n",
       "      <th>GSDP_18_19</th>\n",
       "      <th>Share_2019</th>\n",
       "      <th>GDP_USD_billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP_19_20 GSDP_18_19 Share_2019  \\\n",
       "0     1                Maharashtra          -  2,632,792     13.94%   \n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208      8.63%   \n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764      8.39%   \n",
       "3     4                    Gujarat          -  1,502,899      7.96%   \n",
       "4     5                  Karnataka  1,631,977  1,493,127      7.91%   \n",
       "5     6                West Bengal  1,253,832  1,089,898      5.77%   \n",
       "6     7                  Rajasthan  1,020,989    942,586      4.99%   \n",
       "7     8             Andhra Pradesh    972,782    862,957      4.57%   \n",
       "8     9                  Telangana    969,604    861,031      4.56%   \n",
       "9    10             Madhya Pradesh    906,672    809,592      4.29%   \n",
       "10   11                     Kerala          -    781,653      4.14%   \n",
       "11   12                      Delhi    856,112    774,870      4.10%   \n",
       "12   13                    Haryana    831,610    734,163      3.89%   \n",
       "13   14                      Bihar    611,804    530,363      2.81%   \n",
       "14   15                     Punjab    574,760    526,376      2.79%   \n",
       "15   16                     Odisha    521,275    487,805      2.58%   \n",
       "16   17                      Assam          -    315,881      1.67%   \n",
       "17   18               Chhattisgarh    329,180    304,063      1.61%   \n",
       "18   19                  Jharkhand    328,598    297,204      1.57%   \n",
       "19   20                Uttarakhand          -    245,895      1.30%   \n",
       "20   21            Jammu & Kashmir          -    155,956      0.83%   \n",
       "21   22           Himachal Pradesh    165,472    153,845      0.81%   \n",
       "22   23                        Goa     80,449     73,170      0.39%   \n",
       "23   24                    Tripura     55,984     49,845      0.26%   \n",
       "24   25                 Chandigarh          -     42,114      0.22%   \n",
       "25   26                 Puducherry     38,253     34,433      0.18%   \n",
       "26   27                  Meghalaya     36,572     33,481      0.18%   \n",
       "27   28                     Sikkim     32,496     28,723      0.15%   \n",
       "28   29                    Manipur     31,790     27,870      0.15%   \n",
       "29   30                   Nagaland          -     27,283      0.14%   \n",
       "30   31          Arunachal Pradesh          -     24,603      0.13%   \n",
       "31   32                    Mizoram     26,503     22,287      0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -          -          -   \n",
       "\n",
       "   GDP_USD_billion  \n",
       "0          399.921  \n",
       "1          247.629  \n",
       "2          240.726  \n",
       "3          228.290  \n",
       "4          226.806  \n",
       "5          165.556  \n",
       "6          143.179  \n",
       "7          131.083  \n",
       "8          130.791  \n",
       "9          122.977  \n",
       "10         118.733  \n",
       "11         117.703  \n",
       "12         111.519  \n",
       "13          80.562  \n",
       "14          79.957  \n",
       "15          74.098  \n",
       "16          47.982  \n",
       "17          46.187  \n",
       "18          45.145  \n",
       "19          37.351  \n",
       "20          23.690  \n",
       "21          23.369  \n",
       "22          11.115  \n",
       "23           7.571  \n",
       "24           6.397  \n",
       "25           5.230  \n",
       "26           5.086  \n",
       "27           4.363  \n",
       "28           4.233  \n",
       "29           4.144  \n",
       "30           3.737  \n",
       "31           3.385  \n",
       "32               -  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list\n",
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_19_20=[]\n",
    "GSDP_18_19=[]\n",
    "Share_2019=[]\n",
    "GDP_USD_billion=[]\n",
    "time.sleep(3)\n",
    "\n",
    "# Fetching rank details\n",
    "\n",
    "\n",
    "position = driver.find_elements_by_xpath('//td[@class=\"data1\"]')\n",
    "for i in position:\n",
    "    try:\n",
    "        Rank.append(i.text)\n",
    "    except:\n",
    "        Rank.append('-')\n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "# Fetching State details\n",
    "\n",
    "        \n",
    "state = driver.find_elements_by_xpath('//td[@class=\"name\"]')\n",
    "for i in state:\n",
    "    try:\n",
    "        State.append(i.text)\n",
    "    except:\n",
    "        State.append('-')\n",
    "        \n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    " # Fetching 19-20 details\n",
    "\n",
    "        \n",
    "year_19_20 = driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[3]\")\n",
    "for i in year_19_20:\n",
    "    try:\n",
    "        GSDP_19_20.append(i.text)\n",
    "    except:\n",
    "        GSDP_19_20.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "# Fetching year18-19 details\n",
    "\n",
    "        \n",
    "year_18_19 = driver.find_elements_by_xpath(\"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "for i in year_18_19:\n",
    "    try:\n",
    "        GSDP_18_19.append(i.text)\n",
    "    except:\n",
    "        GSDP_18_19.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "# Fetching Share_2019 details\n",
    "\n",
    "        \n",
    "share = driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "for i in share:\n",
    "    try:\n",
    "        Share_2019.append(i.text)\n",
    "    except:\n",
    "        Share_2019.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "# Fetching billions details\n",
    "\n",
    "        \n",
    "billion = driver.find_elements_by_xpath('//*[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "for i in billion:\n",
    "    try:\n",
    "        GDP_USD_billion.append(i.text)\n",
    "    except:\n",
    "        GDP_USD_billion.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "#creating a dataframe\n",
    "GDP_of_India=pd.DataFrame([])\n",
    "GDP_of_India[\"Rank\"]=Rank[:33]\n",
    "GDP_of_India[\"State\"]=State[:33]\n",
    "GDP_of_India[\"GSDP_19_20\"]=GSDP_19_20[:33]\n",
    "GDP_of_India[\"GSDP_18_19\"]=GSDP_18_19[:33]\n",
    "GDP_of_India[\"Share_2019\"]=Share_2019[:33]\n",
    "GDP_of_India[\"GDP_USD_billion\"]=GDP_USD_billion[:33]\n",
    "GDP_of_India"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "url='https://github.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the explore button\n",
    "explore_button=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "explore_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking trending option\n",
    "trend_opt = driver.find_element_by_xpath(\"//ul[@class='list-style-none mb-3'][2]/li[3]/a\")\n",
    "action.click(trend_opt).perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list\n",
    "Repository_title = []\n",
    "Repository_description= []\n",
    "Contributors_count= []\n",
    "Language_used= []\n",
    "\n",
    "#Fetaching repository title detail\n",
    "repository=driver.find_elements_by_xpath(\"//*[@id='js-pjax-container']/div[3]/div/div[2]/article/h1/a\")\n",
    "for i in repository:\n",
    "    try:\n",
    "        Repository_title.append(i.text)\n",
    "    except:\n",
    "        Repository_title.append(\"-\")\n",
    "        \n",
    "#creating  description detail\n",
    "repo_desc=driver.find_elements_by_xpath(\"//*[@id='js-pjax-container']/div[3]/div/div[2]/article/p\")\n",
    "for i in repo_desc:\n",
    "    try:\n",
    "        Repository_description.append(i.text)\n",
    "    except:\n",
    "        Repository_description.appens(\"-\")\n",
    "        \n",
    "#Fethching  contributor detail\n",
    "contributor=driver.find_elements_by_xpath(\"//*[@id='js-pjax-container']/div[3]/div/div[2]/article/div[2]/a[2]\")\n",
    "for i in contributor:\n",
    "    try:\n",
    "        Contributors_count.append(i.text)\n",
    "    except:\n",
    "        Contributors_count.append(\"-\")\n",
    "\n",
    "#Featching repository language detail\n",
    "lang=driver.find_elements_by_xpath(\"//*[@id='js-pjax-container']/div[3]/div/div[2]/article/div[2]/span[1]/span[2]\")\n",
    "for i in lang:\n",
    "    try:\n",
    "        Language_used.append(i.text)\n",
    "    except:\n",
    "        Language_used.append(\"-\")\n",
    "        \n",
    "        \n",
    "#creating a data frame\n",
    "Trending_repositories=pd.DataFrame([])\n",
    "Trending_repositories[\"Repository_title\"]=Repository_title[0:20]\n",
    "Trending_repositories[\"Repository_description\"]=Repository_description[0:20]\n",
    "Trending_repositories[\"Contributors_count\"]=Contributors_count[0:20]\n",
    "Trending_repositories[\"Language_used\"]=Language_used[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Contributors_count</th>\n",
       "      <th>Language_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SJang1 / korea-covid-19-remaining-vaccine-macro</td>\n",
       "      <td>잔여백신 조회 및 예약 매크로</td>\n",
       "      <td>71</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bradtraversy / 50projects50days</td>\n",
       "      <td>50+ mini web projects using HTML, CSS &amp; JS</td>\n",
       "      <td>1,684</td>\n",
       "      <td>CSS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>freeCodeCamp / freeCodeCamp</td>\n",
       "      <td>freeCodeCamp.org's open-source codebase and cu...</td>\n",
       "      <td>26,195</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bytedance / flutter_ume</td>\n",
       "      <td>UME is an in-app debug kits platform for Flutt...</td>\n",
       "      <td>46</td>\n",
       "      <td>Dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MoonBegonia / ninja</td>\n",
       "      <td>人人可用的开源数据可视化分析工具。</td>\n",
       "      <td>129</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dataease / dataease</td>\n",
       "      <td>🌱《 Spring 手撸专栏》，本专栏以 Spring 源码学习为目的，通过手写简化版 Sp...</td>\n",
       "      <td>120</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fuzhengwei / small-spring</td>\n",
       "      <td>Push-button installer of macOS Catalina, Mojav...</td>\n",
       "      <td>85</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>myspaghetti / macos-virtualbox</td>\n",
       "      <td>Tracking interesting Linux (and UNIX malware)....</td>\n",
       "      <td>708</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>timb-machine / linux-malware</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>A generalized framework for prototyping full-s...</td>\n",
       "      <td>50,611</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ucla-mobility / OpenCDA</td>\n",
       "      <td>The open source Firebase alternative. Follow t...</td>\n",
       "      <td>19</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>supabase / supabase</td>\n",
       "      <td>Node Version Manager - POSIX-compliant bash sc...</td>\n",
       "      <td>732</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>nvm-sh / nvm</td>\n",
       "      <td>GoogleTest - Google Testing and Mocking Framework</td>\n",
       "      <td>5,126</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>google / googletest</td>\n",
       "      <td>The modern web developer’s platform</td>\n",
       "      <td>7,724</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>angular / angular</td>\n",
       "      <td>Roadmap to becoming a web developer in 2021</td>\n",
       "      <td>19,658</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kamranahmedse / developer-roadmap</td>\n",
       "      <td>分享 GitHub 上有趣、入门级的开源项目</td>\n",
       "      <td>24,103</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>521xueweihan / HelloGitHub</td>\n",
       "      <td>Collection of Summer 2022 tech internships!</td>\n",
       "      <td>6,593</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pittcsc / Summer2022-Internships</td>\n",
       "      <td>Web app for adding EU Digital COVID Certificat...</td>\n",
       "      <td>479</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>covidpass-org / covidpass</td>\n",
       "      <td>Node.js library to automate Chromium, Firefox ...</td>\n",
       "      <td>22</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>microsoft / playwright</td>\n",
       "      <td>Official implementation of IoTeX blockchain pr...</td>\n",
       "      <td>1,100</td>\n",
       "      <td>Dart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Repository_title  \\\n",
       "0   SJang1 / korea-covid-19-remaining-vaccine-macro   \n",
       "1                   bradtraversy / 50projects50days   \n",
       "2                       freeCodeCamp / freeCodeCamp   \n",
       "3                           bytedance / flutter_ume   \n",
       "4                               MoonBegonia / ninja   \n",
       "5                               dataease / dataease   \n",
       "6                         fuzhengwei / small-spring   \n",
       "7                    myspaghetti / macos-virtualbox   \n",
       "8                      timb-machine / linux-malware   \n",
       "9             jwasham / coding-interview-university   \n",
       "10                          ucla-mobility / OpenCDA   \n",
       "11                              supabase / supabase   \n",
       "12                                     nvm-sh / nvm   \n",
       "13                              google / googletest   \n",
       "14                                angular / angular   \n",
       "15                kamranahmedse / developer-roadmap   \n",
       "16                       521xueweihan / HelloGitHub   \n",
       "17                 pittcsc / Summer2022-Internships   \n",
       "18                        covidpass-org / covidpass   \n",
       "19                           microsoft / playwright   \n",
       "\n",
       "                               Repository_description Contributors_count  \\\n",
       "0                                    잔여백신 조회 및 예약 매크로                 71   \n",
       "1          50+ mini web projects using HTML, CSS & JS              1,684   \n",
       "2   freeCodeCamp.org's open-source codebase and cu...             26,195   \n",
       "3   UME is an in-app debug kits platform for Flutt...                 46   \n",
       "4                                   人人可用的开源数据可视化分析工具。                129   \n",
       "5   🌱《 Spring 手撸专栏》，本专栏以 Spring 源码学习为目的，通过手写简化版 Sp...                120   \n",
       "6   Push-button installer of macOS Catalina, Mojav...                 85   \n",
       "7   Tracking interesting Linux (and UNIX malware)....                708   \n",
       "8   A complete computer science study plan to beco...                  5   \n",
       "9   A generalized framework for prototyping full-s...             50,611   \n",
       "10  The open source Firebase alternative. Follow t...                 19   \n",
       "11  Node Version Manager - POSIX-compliant bash sc...                732   \n",
       "12  GoogleTest - Google Testing and Mocking Framework              5,126   \n",
       "13                The modern web developer’s platform              7,724   \n",
       "14        Roadmap to becoming a web developer in 2021             19,658   \n",
       "15                             分享 GitHub 上有趣、入门级的开源项目             24,103   \n",
       "16        Collection of Summer 2022 tech internships!              6,593   \n",
       "17  Web app for adding EU Digital COVID Certificat...                479   \n",
       "18  Node.js library to automate Chromium, Firefox ...                 22   \n",
       "19  Official implementation of IoTeX blockchain pr...              1,100   \n",
       "\n",
       "   Language_used  \n",
       "0         Python  \n",
       "1            CSS  \n",
       "2     JavaScript  \n",
       "3           Dart  \n",
       "4     JavaScript  \n",
       "5           Java  \n",
       "6           Java  \n",
       "7          Shell  \n",
       "8         Python  \n",
       "9     TypeScript  \n",
       "10         Shell  \n",
       "11           C++  \n",
       "12    TypeScript  \n",
       "13        Python  \n",
       "14        Python  \n",
       "15    TypeScript  \n",
       "16    TypeScript  \n",
       "17            Go  \n",
       "18    JavaScript  \n",
       "19          Dart  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trending_repositories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "Url = 'https://www.billboard.com/'\n",
    "driver.get(Url)\n",
    "time.sleep(2)\n",
    "\n",
    "#creating empty list\n",
    "Song_Name=[]\n",
    "Artist_Name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_Charts=[]\n",
    "\n",
    "#clicking the Charts button\n",
    "charts=driver.find_element_by_xpath('//*[@id=\"root\"]/div[2]/div[2]/nav/ul/li[6]/a')\n",
    "charts.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the HOT 100 button\n",
    "hot100=driver.find_element_by_xpath('//div[@class=\"three-sixty-bar-detailed-card__image-title font--bold text--uppercase\"]')\n",
    "hot100.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_week_rank</th>\n",
       "      <th>Peak_rank</th>\n",
       "      <th>Weeks_on_Charts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kiss Me More</td>\n",
       "      <td>Doja Cat Featuring SZA</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Build A Bitch</td>\n",
       "      <td>Bella Poarch</td>\n",
       "      <td>84</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>30</td>\n",
       "      <td>Pop Smoke Featuring Bizzy Banks</td>\n",
       "      <td>-</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>You Should Probably Leave</td>\n",
       "      <td>Chris Stapleton</td>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Jealousy, Jealousy</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>87</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Cold Beer Calling My Name</td>\n",
       "      <td>Jameson Rodgers Featuring Luke Combs</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Song_Name                           Artist_Name  \\\n",
       "0                      Butter                                   BTS   \n",
       "1                    Good 4 U                        Olivia Rodrigo   \n",
       "2                  Levitating             Dua Lipa Featuring DaBaby   \n",
       "3                        Stay         The Kid LAROI & Justin Bieber   \n",
       "4                Kiss Me More                Doja Cat Featuring SZA   \n",
       "..                        ...                                   ...   \n",
       "95              Build A Bitch                          Bella Poarch   \n",
       "96                         30       Pop Smoke Featuring Bizzy Banks   \n",
       "97  You Should Probably Leave                       Chris Stapleton   \n",
       "98         Jealousy, Jealousy                        Olivia Rodrigo   \n",
       "99  Cold Beer Calling My Name  Jameson Rodgers Featuring Luke Combs   \n",
       "\n",
       "   Last_week_rank Peak_rank Weeks_on_Charts  \n",
       "0               7         1               9  \n",
       "1               2         1              10  \n",
       "2               4         2              42  \n",
       "3               3         3               2  \n",
       "4               5         3              15  \n",
       "..            ...       ...             ...  \n",
       "95             84        56              10  \n",
       "96              -        97               1  \n",
       "97             91        90               3  \n",
       "98             87        24               9  \n",
       "99             95        95               3  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fetching  song name \n",
    "name=driver.find_elements_by_xpath('//span[@class=\"chart-element__information__song text--truncate color--primary\"]')\n",
    "for i in name:\n",
    "    try:\n",
    "        Song_Name.append(i.text)\n",
    "    except:\n",
    "        Song_Name.append(\"-\")\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "#Fetching  Artist name detail\n",
    "artist=driver.find_elements_by_xpath('//span[@class=\"chart-element__information__artist text--truncate color--secondary\"]')\n",
    "for i in artist:\n",
    "    try:\n",
    "        Artist_Name.append(i.text)\n",
    "    except:\n",
    "        Artist_Name.append(\"-\")\n",
    "\n",
    "        time.sleep(1)\n",
    "            \n",
    "#Fetching  last week detail\n",
    "last_week=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "for i in last_week:\n",
    "    try:\n",
    "        Last_week_rank.append(i.text)\n",
    "    except:\n",
    "        Last_week_rank.append(\"-\")\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "#Fetching peak rank detail\n",
    "peak=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "for i in peak:\n",
    "    try:\n",
    "        Peak_rank.append(i.text)\n",
    "    except:\n",
    "        Peak_rank.append(\"-\")\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "#Fetching weeks on charts detail\n",
    "charts=driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "for i in charts:\n",
    "    try:\n",
    "        Weeks_on_Charts.append(i.text)\n",
    "    except:\n",
    "        Weeks_on_Charts.append(\"-\")\n",
    "\n",
    "        time.sleep(2)\n",
    "        \n",
    "#creating the data frame\n",
    "Top_100_songs=pd.DataFrame([])\n",
    "Top_100_songs[\"Song_Name\"]=Song_Name[:100]\n",
    "Top_100_songs[\"Artist_Name\"]=Artist_Name[:100]\n",
    "Top_100_songs[\"Last_week_rank\"]=Last_week_rank[:100]\n",
    "Top_100_songs[\"Peak_rank\"]=Peak_rank[:100]\n",
    "Top_100_songs[\"Weeks_on_Charts\"]=Weeks_on_Charts[:100]\n",
    "Top_100_songs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "Url = 'https://www.naukri.com/'\n",
    "driver.get(Url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the recruiters button\n",
    "recruiters=driver.find_element_by_xpath('//a[@title=\"Search Recruiters\"]').get_attribute('href')\n",
    "driver.get(recruiters)\n",
    "time.sleep(2)\n",
    "\n",
    "# Searching Datascience position in recruiter page\n",
    "search_box = driver.find_element_by_xpath(\"//div[@class='sWrap lftBrd']/div[2]/input\")\n",
    "search_box.send_keys(\"Data science\")\n",
    "time.sleep(2)\n",
    "\n",
    "search_btn = driver.find_element_by_id(\"qsbFormBtn\")\n",
    "search_btn.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#creating empty list\n",
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills=[]\n",
    "Location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Radha Manivasagam</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Python, Artificial Intelligence, Machine Learn...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Prateek Kumar</td>\n",
       "      <td>Head</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Java, Python, Angularjs, Software Testing, Mac...</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>Techcovery</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>Trisect</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                Kalpana Dumpala   \n",
       "11                                        Mubarak   \n",
       "12                                 Kushal Rastogi   \n",
       "13                                    Ruchi Dhote   \n",
       "14                             Mahesh Babu Channa   \n",
       "15                                   Kapil Devang   \n",
       "16                                  Manisha Yadav   \n",
       "17                                    Riya Rajesh   \n",
       "18                           Rashmi Bhattacharjee   \n",
       "19                                  Faizan Kareem   \n",
       "20                                 Rithika dadwal   \n",
       "21                                  Azahar Shaikh   \n",
       "22                             Sandhya Khandagale   \n",
       "23                                      Shaun Rao   \n",
       "24                                          Manas   \n",
       "25                                          kumar   \n",
       "26                                   Sunil Vedula   \n",
       "27                                    Rajat Kumar   \n",
       "28                                    Priya Khare   \n",
       "29                                Dhruv Dev Dubey   \n",
       "30                                      Jayanth N   \n",
       "31                                       SREEDHAR   \n",
       "32                              Radha Manivasagam   \n",
       "33                                  Prateek Kumar   \n",
       "34                                    Amit Sharma   \n",
       "35                                          Kanan   \n",
       "36                           Shashikant Chaudhary   \n",
       "37                                           Brad   \n",
       "38                                   Rutuja Pawar   \n",
       "39                            Madhusudhan Sridhar   \n",
       "40                                    Ankit Sinha   \n",
       "41                                 Gaurav Chouhan   \n",
       "42                                   Rashi Kacker   \n",
       "43                                        Ashwini   \n",
       "44                                   Balaji Kolli   \n",
       "45                                 Rajani Nagaraj   \n",
       "46                                    ROHIT Kumar   \n",
       "47                                 Amir Chowdhury   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                     Executive Hiring   \n",
       "11                           Company HR   \n",
       "12                           Company HR   \n",
       "13  Senior Executive Talent Acquisition   \n",
       "14                         HR Team Lead   \n",
       "15                           HR Manager   \n",
       "16                         HR Executive   \n",
       "17           Manager Talent Acquisition   \n",
       "18                              HR Head   \n",
       "19                           HR MANAGER   \n",
       "20                         HR Recruiter   \n",
       "21                    Company Recruiter   \n",
       "22                         HR Recruiter   \n",
       "23              Manager Human Resources   \n",
       "24              Lead Talent acquisition   \n",
       "25                           Proprietor   \n",
       "26                                  CEO   \n",
       "27                          Founder CEO   \n",
       "28                       Senior Manager   \n",
       "29             Company Recruitment Head   \n",
       "30                      Project Manager   \n",
       "31               Recruitment Consultant   \n",
       "32                         HR Executive   \n",
       "33                                 Head   \n",
       "34                           Consultant   \n",
       "35         senior technology instructor   \n",
       "36             HR Recruiter/HR Excutive   \n",
       "37        Manager, Technical Recruiting   \n",
       "38                  Technical Recruiter   \n",
       "39                      Erp Implementer   \n",
       "40                       Head Analytics   \n",
       "41              Chief Technical Officer   \n",
       "42                   Sr Product Manager   \n",
       "43             Director Global Delivery   \n",
       "44                           Co Founder   \n",
       "45                           HR Manager   \n",
       "46                            Architect   \n",
       "47                     Managing Partner   \n",
       "\n",
       "                                           Company  \\\n",
       "0                             Data Science Network   \n",
       "1                             Data Science Network   \n",
       "2                             Data Science Network   \n",
       "3                    Shore Infotech India Pvt. Ltd   \n",
       "4                         MARSIAN Technologies LLP   \n",
       "5            Enerlytics Software Solutions Pvt Ltd   \n",
       "6                                  LibraryXProject   \n",
       "7       Apidel Technologies Division of Transpower   \n",
       "8                                             IFMR   \n",
       "9                      Techvantage Systems Pvt Ltd   \n",
       "10                      Weupskill- Live Wire India   \n",
       "11                CBL Data Science Private Limited   \n",
       "12                              Innominds Software   \n",
       "13                                        MoneyTap   \n",
       "14              QuantMagnum Technologies Pvt. Ltd.   \n",
       "15                           Bristlecone India Ltd   \n",
       "16                               SocialPrachar.com   \n",
       "17                                  BISP Solutions   \n",
       "18                                        Easi Tax   \n",
       "19                     Novelworx Digital Solutions   \n",
       "20         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...   \n",
       "21                   FirstTech Consaltants Pvt.Ltd   \n",
       "22                                Affine Analytics   \n",
       "23                 NEAL ANALYTICS SERVICES PVT LTD   \n",
       "24                 Compumatrice Multimedia Pvt Ltd   \n",
       "25                              Exela Technologies   \n",
       "26      Autumn Leaf Consulting Services Private...   \n",
       "27                                         trainin   \n",
       "28                            Nanoprecise Sci Corp   \n",
       "29                  R.S Consultancy &amp; Services   \n",
       "30                          Independent Consultant   \n",
       "31                                    Confidential   \n",
       "32        Dollarbird Information Services Pvt, Ltd   \n",
       "33     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "34                                      Techcovery   \n",
       "35                                         Trisect   \n",
       "36                                 ASCO consulting   \n",
       "37                                         NY INST   \n",
       "38  3D India Staffing Research &amp; Consulting...   \n",
       "39                                     O.C. Tanner   \n",
       "40                                   Demand Matrix   \n",
       "41                             MADHUSUDHAN SRIDHAR   \n",
       "42                                  Suntech Global   \n",
       "43                        Strategic Consulting Lab   \n",
       "44                            Impel Labs Pvt. Ltd.   \n",
       "45                                    MRP Advisers   \n",
       "46                   Saras Solutions India Pvt Ltd   \n",
       "47                                     WildJasmine   \n",
       "\n",
       "                                               Skills  \\\n",
       "0   Classic ASP Developer, Internet Marketing Prof...   \n",
       "1   .Net, Java, Data Science, Linux Administration...   \n",
       "2   Data Science, Artificial Intelligence, Machine...   \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...   \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...   \n",
       "5   Analytics, Business Intelligence, Business Ana...   \n",
       "6                                        Data Science   \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...   \n",
       "8   Technical Training, Software Development, Pres...   \n",
       "9   Software Development, It Sales, Account Manage...   \n",
       "10  Qa, Ui/ux, Java Developer, Java Architect, C++...   \n",
       "11  Business Intelligence, Data Warehousing, Data ...   \n",
       "12  Office Administration, Hr Administration, tele...   \n",
       "13  Qlikview, Qlik Sense, Microsoft Azure, Power B...   \n",
       "14  Social Media, digital media maketing, seo, smm...   \n",
       "15     Big Data, Hadoop, Data Analytics, Data Science   \n",
       "16  Telecalling, Client Interaction, Marketing, Re...   \n",
       "17                                       Data Science   \n",
       "18  Corporate Sales, Software Development, Softwar...   \n",
       "19  Data Analytics, Data Science, Machine Learning...   \n",
       "20  Data Science, Machine Learning, Python, R, Dee...   \n",
       "21  Data Science, Artificial Intelligence, Machine...   \n",
       "22  Big Data, Data Science, Artificial Intelligenc...   \n",
       "23  Java, Net, Angularjs, Hr, Infrastructure, Mana...   \n",
       "24  Software Architecture, Vp Engineering, Product...   \n",
       "25  Data Science, Hadoop, Rpas, Devops, Python, Aw...   \n",
       "26  Signal Processing, Machine Learning, Neural Ne...   \n",
       "27  Web Technologies, Project Management, Software...   \n",
       "28  Data Science, Artificial Intelligence, analyti...   \n",
       "29  Server Administartion, Verilog, Vhdl, Digital ...   \n",
       "30  Data Analytics, Managed Services, Team Leading...   \n",
       "31  Data Science, Machine Learning, Big Data Analy...   \n",
       "32  Python, Artificial Intelligence, Machine Learn...   \n",
       "33  Java, Python, Angularjs, Software Testing, Mac...   \n",
       "34  Machine Learning, Artificial Intelligence, Dat...   \n",
       "35  C, C++, Artificial Intelligence, Python, Php, ...   \n",
       "36  Relationship Management, Retail Sales, Private...   \n",
       "37                 Data Science, Software Engineering   \n",
       "38  Data Science, Big Data Analytics, Digital Mark...   \n",
       "39                  Data Science, Recruitment, Salary   \n",
       "40  B.Tech, Tableau, Statistics, R, Analytics, Tim...   \n",
       "41  Software Development, Business Intelligence, B...   \n",
       "42                   Data Science, Node.js, Angularjs   \n",
       "43  Data Science, Media Marketing, Resource Planni...   \n",
       "44  Data Analysis, Learning, Data Science, Compute...   \n",
       "45  Java, Hadoop, R, Machine Learning, Spark, Flum...   \n",
       "46  Software Development, Core Java, Unit Testing,...   \n",
       "47  Machine Learning, Data Science, Product Manage...   \n",
       "\n",
       "                    Location  \n",
       "0                      Delhi  \n",
       "1   Hyderabad / Secunderabad  \n",
       "2                       Pune  \n",
       "3                  Ahmedabad  \n",
       "4              UK - (london)  \n",
       "5          Vadodara / Baroda  \n",
       "6                    Chennai  \n",
       "7                 Trivandrum  \n",
       "8                     Indore  \n",
       "9      Bengaluru / Bangalore  \n",
       "10  Hyderabad / Secunderabad  \n",
       "11     Bengaluru / Bangalore  \n",
       "12                    Mumbai  \n",
       "13                      Pune  \n",
       "14  Hyderabad / Secunderabad  \n",
       "15                    Bhopal  \n",
       "16               Navi Mumbai  \n",
       "17                    Cochin  \n",
       "18                     Delhi  \n",
       "19  Hyderabad / Secunderabad  \n",
       "20                      Pune  \n",
       "21                      Pune  \n",
       "22                      Pune  \n",
       "23                      Pune  \n",
       "24     Bengaluru / Bangalore  \n",
       "25     Bengaluru / Bangalore  \n",
       "26                     Delhi  \n",
       "27     Bengaluru / Bangalore  \n",
       "28     Bengaluru / Bangalore  \n",
       "29           Mysoru / Mysore  \n",
       "30  Hyderabad / Secunderabad  \n",
       "31     Bengaluru / Bangalore  \n",
       "32                     Noida  \n",
       "33                 New Delhi  \n",
       "34                   Chennai  \n",
       "35                   Aligarh  \n",
       "36            Salt Lake City  \n",
       "37                      Pune  \n",
       "38     Bengaluru / Bangalore  \n",
       "39                    Mumbai  \n",
       "40                    Indore  \n",
       "41     Bengaluru / Bangalore  \n",
       "42                    MYSORE  \n",
       "43  Hyderabad / Secunderabad  \n",
       "44     Bengaluru / Bangalore  \n",
       "45                    Mumbai  \n",
       "46                     Noida  \n",
       "47                    Mumbai  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetching Name detail\n",
    "name= driver.find_elements_by_xpath('//span[@class=\"fl ellipsis\"]')\n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except:\n",
    "        Name.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "# Fetching Designation detail\n",
    "place= driver.find_elements_by_xpath('//span[@class=\"ellipsis clr\"]')\n",
    "for i in place:\n",
    "    try:\n",
    "        Designation.append(i.text)\n",
    "    except:\n",
    "        Designation.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "# Fetching Company detail\n",
    "Organisation= driver.find_elements_by_xpath('//p[@class=\"highlightable\"]/a[2]')\n",
    "for i in Organisation:\n",
    "    try:\n",
    "        Company.append(i.text)\n",
    "    except:\n",
    "        Company.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "# Fetching skills detail\n",
    "roll= driver.find_elements_by_xpath('//div[@class=\"hireSec highlightable\"]')\n",
    "for i in roll:\n",
    "    try:\n",
    "        Skills.append(i.text)\n",
    "    except:\n",
    "        Skills.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "# Fetching Location detail\n",
    "location= driver.find_elements_by_xpath('//small[@class=\"ellipsis\"]')\n",
    "for i in location:\n",
    "    try:\n",
    "        Location.append(i.text)\n",
    "    except:\n",
    "        Location.append('-')\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "#creating the Data Frame\n",
    "Data_scientist_recruiters=pd.DataFrame([])\n",
    "Data_scientist_recruiters[\"Name\"]=Name[:48]\n",
    "Data_scientist_recruiters[\"Designation\"]=Designation[:48]\n",
    "Data_scientist_recruiters[\"Company\"]=Company[:48]\n",
    "Data_scientist_recruiters[\"Skills\"]=Skills[:48]\n",
    "Data_scientist_recruiters[\"Location\"]=Location[:48]\n",
    "Data_scientist_recruiters"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "Url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/'\n",
    "driver.get(Url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Volumes_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Jamie's Italy</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>906,968</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>National &amp; Regional Cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>I Can Make You Thin</td>\n",
       "      <td>McKenna, Paul</td>\n",
       "      <td>905,086</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Fitness &amp; Diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Down Under</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>890,847</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Travel Writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Summons,The</td>\n",
       "      <td>Grisham, John</td>\n",
       "      <td>869,671</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Small Island</td>\n",
       "      <td>Levy, Andrea</td>\n",
       "      <td>869,659</td>\n",
       "      <td>Headline</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Book_Name    Author_Name Volumes_Sold  \\\n",
       "0                           Da Vinci Code,The     Brown, Dan    5,094,805   \n",
       "1        Harry Potter and the Deathly Hallows  Rowling, J.K.    4,475,152   \n",
       "2    Harry Potter and the Philosopher's Stone  Rowling, J.K.    4,200,654   \n",
       "3   Harry Potter and the Order of the Phoenix  Rowling, J.K.    4,179,479   \n",
       "4                        Fifty Shades of Grey   James, E. L.    3,758,936   \n",
       "..                                        ...            ...          ...   \n",
       "78                              Jamie's Italy  Oliver, Jamie      906,968   \n",
       "79                        I Can Make You Thin  McKenna, Paul      905,086   \n",
       "80                                 Down Under   Bryson, Bill      890,847   \n",
       "81                                Summons,The  Grisham, John      869,671   \n",
       "82                               Small Island   Levy, Andrea      869,659   \n",
       "\n",
       "       Publisher                        Genre  \n",
       "0     Transworld  Crime, Thriller & Adventure  \n",
       "1     Bloomsbury           Children's Fiction  \n",
       "2     Bloomsbury           Children's Fiction  \n",
       "3     Bloomsbury           Children's Fiction  \n",
       "4   Random House              Romance & Sagas  \n",
       "..           ...                          ...  \n",
       "78       Penguin  National & Regional Cuisine  \n",
       "79    Transworld               Fitness & Diet  \n",
       "80    Transworld               Travel Writing  \n",
       "81  Random House  Crime, Thriller & Adventure  \n",
       "82      Headline                               \n",
       "\n",
       "[83 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list\n",
    "Book_Name=[]\n",
    "Author_Name=[]\n",
    "Volumes_Sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "#Fetching book name detail\n",
    "bookname=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[2]\")\n",
    "for i in bookname:\n",
    "    try:\n",
    "        Book_Name.append(i.text)\n",
    "    except:\n",
    "        Book_Name.append(\"-\")\n",
    "        \n",
    "#Fetching author name detail\n",
    "authorname=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[3]\")\n",
    "for i in authorname:\n",
    "    try:\n",
    "        Author_Name.append(i.text)\n",
    "    except:\n",
    "        Author_Name.append(\"-\")\n",
    "        \n",
    "#Fetching volumes sold detail\n",
    "volumesold=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[4]\")\n",
    "for i in volumesold:\n",
    "    try:\n",
    "        Volumes_Sold.append(i.text)\n",
    "    except:\n",
    "        Volumes_Sold.append(\"-\")\n",
    "        \n",
    "#Fetching publisher detail\n",
    "publisher=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[5]\")\n",
    "for i in publisher:\n",
    "    try:\n",
    "        Publisher.append(i.text)\n",
    "    except:\n",
    "        Publisher.append(\"-\")\n",
    "        \n",
    "#Fetching genre detail\n",
    "genre=driver.find_elements_by_xpath(\"/html/body/div/div[2]/div[2]/div/div[2]/div/table/tbody/tr/td[6]\")\n",
    "for i in genre:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except:\n",
    "        Genre.append(\"-\")\n",
    " \n",
    "    #creating Data Frame\n",
    "Highest_selling_novels=pd.DataFrame([])\n",
    "Highest_selling_novels[\"Book_Name\"]=Book_Name\n",
    "Highest_selling_novels[\"Author_Name\"]=Author_Name\n",
    "Highest_selling_novels[\"Volumes_Sold\"]=Volumes_Sold\n",
    "Highest_selling_novels[\"Publisher\"]=Publisher\n",
    "Highest_selling_novels[\"Genre\"]=Genre\n",
    "Highest_selling_novels"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    " Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "url = ('https://www.imdb.com/list/ls095964455/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,844,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>882,884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>884,028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>265,531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>226,580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orange Is the New Black</td>\n",
       "      <td>(2013–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>59 min</td>\n",
       "      <td>8</td>\n",
       "      <td>284,202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Riverdale</td>\n",
       "      <td>(2017– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>6.8</td>\n",
       "      <td>125,816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grey's Anatomy</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>265,587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Flash</td>\n",
       "      <td>(2014– )</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>319,386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arrow</td>\n",
       "      <td>(2012–2020)</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>414,280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Money Heist</td>\n",
       "      <td>(2017–2021)</td>\n",
       "      <td>Action, Crime, Mystery</td>\n",
       "      <td>70 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>340,577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>(2007–2019)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>742,376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Black Mirror</td>\n",
       "      <td>(2011– )</td>\n",
       "      <td>Drama, Sci-Fi, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>468,419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sherlock</td>\n",
       "      <td>(2010–2017)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>88 min</td>\n",
       "      <td>9.1</td>\n",
       "      <td>837,627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vikings</td>\n",
       "      <td>(2013–2020)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>458,778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pretty Little Liars</td>\n",
       "      <td>(2010–2017)</td>\n",
       "      <td>Drama, Mystery, Romance</td>\n",
       "      <td>44 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>155,677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Vampire Diaries</td>\n",
       "      <td>(2009–2017)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>292,997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>American Horror Story</td>\n",
       "      <td>(2011– )</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8</td>\n",
       "      <td>285,767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>(2008–2013)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>49 min</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1,548,565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lucifer</td>\n",
       "      <td>(2016–2021)</td>\n",
       "      <td>Crime, Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>262,912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Supernatural</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>403,590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Prison Break</td>\n",
       "      <td>(2005–2017)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>491,728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How to Get Away with Murder</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>43 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>135,831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011–2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>132,661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989– )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>374,901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Once Upon a Time</td>\n",
       "      <td>(2011–2018)</td>\n",
       "      <td>Adventure, Fantasy, Romance</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>212,400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Narcos</td>\n",
       "      <td>(2015–2017)</td>\n",
       "      <td>Biography, Crime, Drama</td>\n",
       "      <td>49 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>374,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Daredevil</td>\n",
       "      <td>(2015–2018)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>54 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>374,249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Friends</td>\n",
       "      <td>(1994–2004)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>878,680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>How I Met Your Mother</td>\n",
       "      <td>(2005–2014)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>623,161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Suits</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>373,709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Mr. Robot</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>49 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>345,167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The Originals</td>\n",
       "      <td>(2013–2018)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>122,366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Supergirl</td>\n",
       "      <td>(2015–2021)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>43 min</td>\n",
       "      <td>6.2</td>\n",
       "      <td>115,157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Gossip Girl</td>\n",
       "      <td>(2007–2012)</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>159,333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sense8</td>\n",
       "      <td>(2015–2018)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>143,847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gotham</td>\n",
       "      <td>(2014–2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>216,137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Westworld</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>62 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>443,903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Jessica Jones</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>56 min</td>\n",
       "      <td>7.9</td>\n",
       "      <td>197,719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Modern Family</td>\n",
       "      <td>(2009–2020)</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>376,959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Rick and Morty</td>\n",
       "      <td>(2013– )</td>\n",
       "      <td>Animation, Adventure, Comedy</td>\n",
       "      <td>23 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>412,388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Shadowhunters</td>\n",
       "      <td>(2016–2019)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>6.6</td>\n",
       "      <td>56,050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The End of the F***ing World</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Crime</td>\n",
       "      <td>25 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>157,271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>House of Cards</td>\n",
       "      <td>(2013–2018)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>476,125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Dark</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>311,720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Elite</td>\n",
       "      <td>(2018– )</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>59,391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Sex Education</td>\n",
       "      <td>(2019– )</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>176,485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Shameless</td>\n",
       "      <td>(2011–2021)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>46 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>212,815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>New Girl</td>\n",
       "      <td>(2011–2018)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>200,091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Agents of S.H.I.E.L.D.</td>\n",
       "      <td>(2013–2020)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>204,855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>You</td>\n",
       "      <td>(2018– )</td>\n",
       "      <td>Crime, Drama, Romance</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>157,088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Dexter</td>\n",
       "      <td>(2006–2013)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>53 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>664,033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Fear the Walking Dead</td>\n",
       "      <td>(2015– )</td>\n",
       "      <td>Drama, Horror, Sci-Fi</td>\n",
       "      <td>44 min</td>\n",
       "      <td>6.9</td>\n",
       "      <td>117,715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name    Year_Span                         Genre  \\\n",
       "0                Game of Thrones  (2011–2019)      Action, Adventure, Drama   \n",
       "1                Stranger Things     (2016– )        Drama, Fantasy, Horror   \n",
       "2               The Walking Dead  (2010–2022)       Drama, Horror, Thriller   \n",
       "3                 13 Reasons Why  (2017–2020)      Drama, Mystery, Thriller   \n",
       "4                        The 100  (2014–2020)        Drama, Mystery, Sci-Fi   \n",
       "5        Orange Is the New Black  (2013–2019)          Comedy, Crime, Drama   \n",
       "6                      Riverdale     (2017– )         Crime, Drama, Mystery   \n",
       "7                 Grey's Anatomy     (2005– )                Drama, Romance   \n",
       "8                      The Flash     (2014– )      Action, Adventure, Drama   \n",
       "9                          Arrow  (2012–2020)      Action, Adventure, Crime   \n",
       "10                   Money Heist  (2017–2021)        Action, Crime, Mystery   \n",
       "11           The Big Bang Theory  (2007–2019)               Comedy, Romance   \n",
       "12                  Black Mirror     (2011– )       Drama, Sci-Fi, Thriller   \n",
       "13                      Sherlock  (2010–2017)         Crime, Drama, Mystery   \n",
       "14                       Vikings  (2013–2020)      Action, Adventure, Drama   \n",
       "15           Pretty Little Liars  (2010–2017)       Drama, Mystery, Romance   \n",
       "16           The Vampire Diaries  (2009–2017)        Drama, Fantasy, Horror   \n",
       "17         American Horror Story     (2011– )       Drama, Horror, Thriller   \n",
       "18                  Breaking Bad  (2008–2013)        Crime, Drama, Thriller   \n",
       "19                       Lucifer  (2016–2021)         Crime, Drama, Fantasy   \n",
       "20                  Supernatural  (2005–2020)        Drama, Fantasy, Horror   \n",
       "21                  Prison Break  (2005–2017)          Action, Crime, Drama   \n",
       "22   How to Get Away with Murder  (2014–2020)         Crime, Drama, Mystery   \n",
       "23                     Teen Wolf  (2011–2017)        Action, Drama, Fantasy   \n",
       "24                  The Simpsons     (1989– )             Animation, Comedy   \n",
       "25              Once Upon a Time  (2011–2018)   Adventure, Fantasy, Romance   \n",
       "26                        Narcos  (2015–2017)       Biography, Crime, Drama   \n",
       "27                     Daredevil  (2015–2018)          Action, Crime, Drama   \n",
       "28                       Friends  (1994–2004)               Comedy, Romance   \n",
       "29         How I Met Your Mother  (2005–2014)               Comedy, Romance   \n",
       "30                         Suits  (2011–2019)                 Comedy, Drama   \n",
       "31                     Mr. Robot  (2015–2019)        Crime, Drama, Thriller   \n",
       "32                 The Originals  (2013–2018)        Drama, Fantasy, Horror   \n",
       "33                     Supergirl  (2015–2021)      Action, Adventure, Drama   \n",
       "34                   Gossip Girl  (2007–2012)                Drama, Romance   \n",
       "35                        Sense8  (2015–2018)        Drama, Mystery, Sci-Fi   \n",
       "36                        Gotham  (2014–2019)          Action, Crime, Drama   \n",
       "37                     Westworld     (2016– )        Drama, Mystery, Sci-Fi   \n",
       "38                 Jessica Jones  (2015–2019)          Action, Crime, Drama   \n",
       "39                 Modern Family  (2009–2020)        Comedy, Drama, Romance   \n",
       "40                Rick and Morty     (2013– )  Animation, Adventure, Comedy   \n",
       "41                 Shadowhunters  (2016–2019)        Action, Drama, Fantasy   \n",
       "42  The End of the F***ing World  (2017–2019)      Adventure, Comedy, Crime   \n",
       "43                House of Cards  (2013–2018)                         Drama   \n",
       "44                          Dark  (2017–2020)         Crime, Drama, Mystery   \n",
       "45                         Elite     (2018– )        Crime, Drama, Thriller   \n",
       "46                 Sex Education     (2019– )                 Comedy, Drama   \n",
       "47                     Shameless  (2011–2021)                 Comedy, Drama   \n",
       "48                      New Girl  (2011–2018)                        Comedy   \n",
       "49        Agents of S.H.I.E.L.D.  (2013–2020)      Action, Adventure, Drama   \n",
       "50                           You     (2018– )         Crime, Drama, Romance   \n",
       "51                        Dexter  (2006–2013)         Crime, Drama, Mystery   \n",
       "52         Fear the Walking Dead     (2015– )         Drama, Horror, Sci-Fi   \n",
       "\n",
       "   Run_Time Ratings      Votes  \n",
       "0    57 min     9.2  1,844,700  \n",
       "1    51 min     8.7    882,884  \n",
       "2    44 min     8.2    884,028  \n",
       "3    60 min     7.6    265,531  \n",
       "4    43 min     7.6    226,580  \n",
       "5    59 min       8    284,202  \n",
       "6    45 min     6.8    125,816  \n",
       "7    41 min     7.5    265,587  \n",
       "8    43 min     7.6    319,386  \n",
       "9    42 min     7.5    414,280  \n",
       "10   70 min     8.3    340,577  \n",
       "11   22 min     8.1    742,376  \n",
       "12   60 min     8.8    468,419  \n",
       "13   88 min     9.1    837,627  \n",
       "14   44 min     8.5    458,778  \n",
       "15   44 min     7.4    155,677  \n",
       "16   43 min     7.7    292,997  \n",
       "17   60 min       8    285,767  \n",
       "18   49 min     9.4  1,548,565  \n",
       "19   42 min     8.1    262,912  \n",
       "20   44 min     8.4    403,590  \n",
       "21   44 min     8.3    491,728  \n",
       "22   43 min     8.1    135,831  \n",
       "23   41 min     7.6    132,661  \n",
       "24   22 min     8.6    374,901  \n",
       "25   60 min     7.7    212,400  \n",
       "26   49 min     8.8    374,600  \n",
       "27   54 min     8.6    374,249  \n",
       "28   22 min     8.9    878,680  \n",
       "29   22 min     8.3    623,161  \n",
       "30   44 min     8.4    373,709  \n",
       "31   49 min     8.5    345,167  \n",
       "32   45 min     8.2    122,366  \n",
       "33   43 min     6.2    115,157  \n",
       "34   42 min     7.4    159,333  \n",
       "35   60 min     8.3    143,847  \n",
       "36   42 min     7.8    216,137  \n",
       "37   62 min     8.6    443,903  \n",
       "38   56 min     7.9    197,719  \n",
       "39   22 min     8.4    376,959  \n",
       "40   23 min     9.2    412,388  \n",
       "41   42 min     6.6     56,050  \n",
       "42   25 min     8.1    157,271  \n",
       "43   51 min     8.7    476,125  \n",
       "44   60 min     8.8    311,720  \n",
       "45   60 min     7.5     59,391  \n",
       "46   45 min     8.3    176,485  \n",
       "47   46 min     8.5    212,815  \n",
       "48   22 min     7.7    200,091  \n",
       "49   45 min     7.5    204,855  \n",
       "50   45 min     7.7    157,088  \n",
       "51   53 min     8.6    664,033  \n",
       "52   44 min     6.9    117,715  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Empty list\n",
    "Name =[]\n",
    "Year_span = []\n",
    "Genre= []\n",
    "Run_Time= []\n",
    "Ratings= []\n",
    "Votes = []\n",
    "\n",
    "#Fetching  name list\n",
    "name=driver.find_elements_by_xpath(\"//*[@id='main']/div/div[3]/div[3]/div/div[2]/h3/a\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except:\n",
    "        Name.append(\"-\")\n",
    "        \n",
    "        \n",
    "year=driver.find_elements_by_xpath('//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "for i in year:\n",
    "    try:\n",
    "        Year_span.append(i.text)\n",
    "    except:\n",
    "        Year_span.append(\"-\")\n",
    "        \n",
    "genre=driver.find_elements_by_xpath('//span[@class=\"genre\"]')\n",
    "for i in genre:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except:\n",
    "        Genre.append(\"-\")\n",
    "        \n",
    "run=driver.find_elements_by_xpath('//span[@class=\"runtime\"]')\n",
    "for i in run:\n",
    "    try:\n",
    "        Run_Time.append(i.text)\n",
    "    except:\n",
    "            Run_Time.append(\"-\")\n",
    "        \n",
    "ratings=driver.find_elements_by_xpath(\"//div[@class ='ipl-rating-star small']/span[2]\")\n",
    "for i in ratings:\n",
    "    try:\n",
    "        Ratings.append(i.text)\n",
    "    except:\n",
    "        Ratings.append(\"-\")\n",
    "        \n",
    "votes=driver.find_elements_by_xpath('//span[@name=\"nv\"]')[:53]\n",
    "for i in votes:\n",
    "    try:\n",
    "        Votes.append(i.text)\n",
    "    except:\n",
    "        Votes.append(\"-\")\n",
    "\n",
    "#creating Data frame\n",
    "Most_watched_tv_series=pd.DataFrame([])\n",
    "Most_watched_tv_series[\"Name\"]=Name[:53]\n",
    "Most_watched_tv_series[\"Year_Span\"]=Year_span[:53]\n",
    "Most_watched_tv_series[\"Genre\"]=Genre[:53]\n",
    "Most_watched_tv_series[\"Run_Time\"]=Run_Time[:53]\n",
    "Most_watched_tv_series[\"Ratings\"]=Ratings[:53]\n",
    "Most_watched_tv_series[\"Votes\"]=Votes[:53]\n",
    "Most_watched_tv_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    " Url = https://archive.ics.uci.edu/\n",
    " You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access chrome browser using webdrive\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "time.sleep(3)\n",
    "\n",
    "# Acess the website\n",
    "url = ('https://archive.ics.uci.edu/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking the viewall data-set button\n",
    "viewall = driver.find_element_by_xpath('/html/body/table[2]/tbody/tr/td/span/b/a')\n",
    "viewall.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty list\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attributes=[]\n",
    "Year=[]\n",
    "\n",
    "#Fetching name detail\n",
    "\n",
    "name = driver.find_elements_by_xpath(\"//p[@class='normal']/b/a\")\n",
    "for i in name:\n",
    "    try:\n",
    "        Dataset_name.append(i.text)\n",
    "    except:\n",
    "        Dataset_name.append('-') \n",
    "        \n",
    "#Fetching datatype detail\n",
    "        \n",
    "dtype = driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]/p')\n",
    "for i in dtype:\n",
    "    try:\n",
    "        Data_type.append(i.text)\n",
    "    except:\n",
    "        Data_type.append('-') \n",
    " #Fetching task detail\n",
    "       \n",
    "default_task = driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]/p')\n",
    "for i in default_task:\n",
    "    try:\n",
    "        Task.append(i.text)\n",
    "    except:\n",
    "        Task.append('-')\n",
    "\n",
    "#Fetching Attribute_type detail\n",
    "        \n",
    "Attritype = driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]/p')\n",
    "for i in Attritype:\n",
    "    try:\n",
    "        Attribute_type.append(i.text)\n",
    "    except:\n",
    "        Attribute_type.append('-') \n",
    "        \n",
    "#Fetching Attribute_type detail   \n",
    "\n",
    "instances = driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]/p')\n",
    "for i in instances:\n",
    "    try:\n",
    "        No_of_instances.append(i.text)\n",
    "    except:\n",
    "        No_of_instances.append('-') \n",
    "        \n",
    "attributes = driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]/p')\n",
    "for i in attributes:\n",
    "    try:\n",
    "        No_of_attributes.append(i.text)\n",
    "    except:\n",
    "        No_of_attributes.append('-') \n",
    "   #Fetching year detail     \n",
    "year = driver.find_elements_by_xpath('/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]/p')\n",
    "for i in year:\n",
    "    try:\n",
    "        Year.append(i.text)\n",
    "    except:\n",
    "        Year.append('-') \n",
    "        \n",
    "#creating Data Frame\n",
    "Details_of_Datasets=pd.DataFrame([])\n",
    "Details_of_Datasets[\"Dataset_name\"]=Dataset_name[:588]\n",
    "Details_of_Datasets[\"Data_type\"]=Data_type[:588]\n",
    "Details_of_Datasets[\"Task\"]=Task[:588]\n",
    "Details_of_Datasets[\"Attribute_type\"]=Attribute_type[:588]\n",
    "Details_of_Datasets[\"No_of_instances\"]=No_of_instances[:588]\n",
    "Details_of_Datasets[\"No_of_attributes\"]=No_of_attributes[:588]\n",
    "Details_of_Datasets[\"Year\"]=Year[:588]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Data Types</td>\n",
       "      <td>Default Task</td>\n",
       "      <td>Attribute Types</td>\n",
       "      <td># Attributes</td>\n",
       "      <td># Attributes</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>294</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>321</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>1068</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>1068</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Dataset_name      Data_type                  Task  \\\n",
       "0                             Abalone     Data Types          Default Task   \n",
       "1                               Adult  Multivariate        Classification    \n",
       "2                           Annealing  Multivariate        Classification    \n",
       "3        Anonymous Microsoft Web Data  Multivariate        Classification    \n",
       "4                          Arrhythmia                 Recommender-Systems    \n",
       "..                                ...            ...                   ...   \n",
       "583  in-vehicle coupon recommendation  Multivariate        Classification    \n",
       "584               Gait Classification  Multivariate        Classification    \n",
       "585         Wikipedia Math Essentials  Multivariate        Classification    \n",
       "586         Wikipedia Math Essentials   Time-Series            Regression    \n",
       "587      Synchronous Machine Data Set   Time-Series            Regression    \n",
       "\n",
       "                  Attribute_type No_of_instances No_of_attributes   Year  \n",
       "0                Attribute Types    # Attributes     # Attributes   Year  \n",
       "1    Categorical, Integer, Real               8                8   1995   \n",
       "2          Categorical, Integer              14               14   1996   \n",
       "3    Categorical, Integer, Real              38               38          \n",
       "4                   Categorical             294              294   1998   \n",
       "..                           ...             ...              ...    ...  \n",
       "583               Integer, Real              17               17   2020   \n",
       "584                                          23               23   2020   \n",
       "585                        Real             321              321   2020   \n",
       "586                        Real            1068             1068   2021   \n",
       "587                        Real            1068             1068   2021   \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Details_of_Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
